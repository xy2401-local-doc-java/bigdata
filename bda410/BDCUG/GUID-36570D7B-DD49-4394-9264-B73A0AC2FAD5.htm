<!DOCTYPE html>
<html lang="en-US" >
<head>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta charset="utf-8">
<meta http-equiv="Content-Type" content="UTF-8" />
<title>Using Oracle's Hive Storage Handler for Kafka to Create a Hive External Table for Kafka Topics</title>
<meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)" />
<meta name="description" content="The Hive storage handler for Kafka enables Hive (as well as Oracle Big Data SQL) to query Kafka topics." />
<meta name="dcterms.created" content="2017-10-10T14:24:14Z" />
<meta name="robots" content="all" />
<meta name="dcterms.title" content="Big Data Connectors User's Guide" />
<meta name="dcterms.identifier" content="E89802-02" />
<meta name="dcterms.isVersionOf" content="BDCUG" />
<meta name="dcterms.rights" content="Copyright&nbsp;&copy;&nbsp;2011, 2017, Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved." />
<link rel="Start" href="http://docs.oracle.com/bigdata/bda49/index.html" title="Home" type="text/html" />
<link rel="Copyright" href="../dcommon/html/cpyr.htm" title="Copyright" type="text/html" />

<script type="application/javascript"  src="../dcommon/js/headfoot.js"></script>
<script type="application/javascript"  src="../nav/js/doccd.js" charset="UTF-8"></script>
<link rel="Contents" href="toc.htm" title="Contents" type="text/html" />
<link rel="Index" href="index.htm" title="Index" type="text/html" />
<link rel="Prev" href="GUID-395691AB-AD99-488B-96D3-CC1D8C1873B7.htm" title="Previous" type="text/html" />
<link rel="Next" href="GUID-6A9F1DDF-B5FF-4062-B038-8FDEF5FBEBE2.htm" title="Next" type="text/html" />
<link rel="alternate" href="BDCUG.pdf" title="PDF version" type="application/pdf" />
<link rel="schema.dcterms" href="http://purl.org/dc/terms/" />
<link rel="stylesheet" href="../dcommon/css/fusiondoc.css">
<link rel="stylesheet" type="text/css"  href="../dcommon/css/header.css">
<link rel="stylesheet" type="text/css"  href="../dcommon/css/footer.css">
<link rel="stylesheet" type="text/css"  href="../dcommon/css/fonts.css">
<link rel="stylesheet" href="../dcommon/css/foundation.css">
<link rel="stylesheet" href="../dcommon/css/codemirror.css">
<link rel="stylesheet" type="text/css" title="Default" href="../nav/css/html5.css">
<link rel="stylesheet" href="../dcommon/css/respond-480-tablet.css">
<link rel="stylesheet" href="../dcommon/css/respond-768-laptop.css">
<link rel="stylesheet" href="../dcommon/css/respond-1140-deskop.css">
<script type="application/javascript" src="../dcommon/js/modernizr.js"></script>
<script type="application/javascript" src="../dcommon/js/codemirror.js"></script>
<script type="application/javascript" src="../dcommon/js/jquery.js"></script>
<script type="application/javascript" src="../dcommon/js/foundation.min.js"></script>
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-552992c80ef99c8d" async="async"></script>
<script type="application/javascript" src="../dcommon/js/jqfns.js"></script>
<script type="application/javascript" src="../dcommon/js/ohc-inline-videos.js"></script>
<!-- Add fancyBox -->
<link rel="stylesheet" href="../dcommon/fancybox/jquery.fancybox.css?v=2.1.5" type="text/css" media="screen" />
<script type="text/javascript" src="../dcommon/fancybox/jquery.fancybox.pack.js?v=2.1.5"></script>
<!-- Optionally add helpers - button, thumbnail and/or media -->
<link rel="stylesheet"  href="../dcommon/fancybox/helpers/jquery.fancybox-buttons.css?v=1.0.5"  type="text/css" media="screen" />
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-buttons.js?v=1.0.5"></script>
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-media.js?v=1.0.6"></script>
<link rel="stylesheet"  href="../dcommon/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7"  type="text/css" media="screen" />
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-thumbs.js?v=1.0.7"></script>
<script>window.ohcglobal || document.write('<script src="/en/dcommon/js/global.js">\x3C/script>')</script></head>
<body>
<a href="#BEGIN" class="accessibility-top skipto" tabindex="0">Go to main content</a><header><!--
<div class="zz-skip-header"><a id="top" href="#BEGIN">Go to main content</a>--></header>
<div class="row" id="CONTENT">
<div class="IND large-9 medium-8 columns" dir="ltr">
<a id="BEGIN" name="BEGIN"></a>
<a id="GUID-36570D7B-DD49-4394-9264-B73A0AC2FAD5"></a> <span id="PAGE" style="display:none;">29/31</span> <!-- End Header -->
<h1 id="BDCUG-GUID-36570D7B-DD49-4394-9264-B73A0AC2FAD5" class="sect1"><span class="enumeration_appendix">B</span> Using Oracle's Hive Storage Handler for Kafka to Create a Hive External Table for Kafka Topics</h1>
<div>
<p>The Hive storage handler for Kafka enables Hive (as well as Oracle Big Data SQL) to query Kafka topics.</p>
<div class="section">
<p>To provide access to Kafka data, you create a Hive external table over the Kafka topics. The Oracle Big Data SQL storage handler that enables Hive to read the Kafka data format is <code class="codeph">oracle.hadoop.kafka.hive.KafkaStorageHandler</code> .</p>
<p>You can use this storage handler to create external Hive tables backed by data residing in Kafka. Big Data SQL can then query the Kafka data through the external Hive tables. &nbsp;</p>
<p>The Hive DDL is demonstrated by the following example, where topic1 and topic2 are two topics in Kafka broker whose keys are serialized by Kafka's String serializer and whose values are serialized by kafka's Long serializer.</p>
<pre dir="ltr">
CREATE EXTERNAL TABLE test_table
row format serde &lsquo;oracle.hadoop.kafka.hive.KafkaSerDe&rsquo;
stored by 'oracle.hadoop.kafka.hive.KafkaStorageHandler'
tblproperties('oracle.kafka.table.key.type'='string',
                     'oracle.kafka.table.value.type'='long',
                     'oracle.kafka.bootstrap.servers'='nshgc0602:9092',
                     'oracle.kafka.table.topics'='topic1,topic2');
</pre>
<p>The example below shows the resulting Hive table. The Kafka key, value, offset, topic name, and partitionid are mapped to Hive columns.&nbsp;&nbsp;You can explicitly designate the offset for each topic/partition pair through a WHERE clause in you Hive query.&nbsp;&nbsp;</p>
<pre dir="ltr">
hive&gt; describe test_table;
OK
topic            string                 from deserializer   
partitionid      int                    from deserializer   
key              string                 from deserializer   
value            bigInt                 from deserializer   
offset           bigint                 from deserializer
timestamptype    smallInt            from deserializer
timestamp        timestamp           from deserializer
Time taken: 0.084 seconds, Fetched: 7 row(s) 
</pre>
<div class="p">The content of the table is a snapshot of the Kafka topics when the Hive query is executed. When new data is inserted into the Kafka topics, you can use the offset column or the timestamp column to track the changes to the topic. The offsets are per topic/partition. For example, the following query will return new messages after the specified offsets in the where clause for each topic/partition:
<pre dir="ltr">
hive&gt; select * from test_table where (topic="topic1" and partitoinid=0 and offset &gt; 199) or (topic="topic1" and partitionid=1 and offset &gt; 198) or (topic="topic2" and partitionid=0 and offset &gt; 177) or (topic="topic2" and partitionid=1 and offset &gt; 176);
</pre>
You need to keep track of the offsets for all topic/partition. For example, you can use an Oracle table to store these offsets. A more convenient way to keep track of new data is using the timestamp column. You can query data after a specific time point using the following query:
<pre dir="ltr">
hive&gt; select * from test_table where timestamp &gt; '2017-07-12 11:30:00'; 
</pre></div>
<p>See the Property Reference section below for descriptions of all table properties</p>
</div>
<!-- class="section" -->
<div class="section">
<p class="subhead1">Property Reference</p>
<div class="tblformal" id="GUID-36570D7B-DD49-4394-9264-B73A0AC2FAD5__GUID-5F14101E-7958-4A53-9BAD-16881CF67A81">
<p class="titleintable">Table B-1 Table Properties of Hive Storage Handler for Kafka</p>
<table class="cellalignment41">
<thead>
<tr class="cellalignment2">
<th class="cellalignment13" id="d74932e54">Property Name</th>
<th class="cellalignment13" id="d74932e57">Requirement</th>
<th class="cellalignment13" id="d74932e60">Description</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment2">
<td class="cellalignment2" rowspan="1" colspan="1" id="d74932e65" headers="d74932e54">
<p><span class="bold">oracle.kafka.table.topics</span></p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e65 d74932e57">
<p>Required</p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e65 d74932e60">
<p>A comma-separated list of Kafka topics. Each Kafka topic name must consists of only letters (uppercase and lowercase), numbers, .(dot), _(underscore), and -(minus). The maximum length for each topic name is 249. These topics must have the same serialization mechanisms. The resulting Hive table consists of records from all the topics listed here. A Hive column &ldquo;topic&rdquo; will be added and it will be set to the topic name for each record.</p>
</td>
</tr>
<tr class="cellalignment2">
<td class="cellalignment2" rowspan="1" colspan="1" id="d74932e76" headers="d74932e54">
<p><span class="bold">oracle.kafka.bootstrap.servers</span></p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e76 d74932e57">
<p>Required</p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e76 d74932e60">
<p>This property will be translated to the &ldquo;bootstrap.servers&rdquo; property for the underlying Kafka consumer. The consumer makes use of all servers, irrespective of which servers are specified here for bootstrapping. This list only impacts the initial hosts used to discover the full set of servers. This list should be in the form <code class="codeph">host1:port1,host2:port2,....</code> Since these servers are just used for the initial connection to discover the full cluster membership (which may change dynamically), this list need not contain the full set of servers. For availability reasons, you may want to list more than one server.</p>
</td>
</tr>
<tr class="cellalignment2">
<td class="cellalignment2" rowspan="1" colspan="1" id="d74932e90" headers="d74932e54">
<p><span class="bold">oracle.kafka.table.key.type</span></p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e90 d74932e57">
<p>Optional</p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e90 d74932e60">
<p>The key type for your record. If unset, then the key part of the Kafka record will be ignored in the Hive row. Only values of &ldquo;string&rdquo;, &ldquo;integer&rdquo;, &ldquo;long&rdquo;, &ldquo;double&rdquo;, &ldquo;avro&rdquo;, &ldquo;avro_confluent&rdquo;are supported. &ldquo;string&rdquo;, &ldquo;integer&rdquo;, &ldquo;double&rdquo; and &ldquo;long&rdquo; correspond to the built-in primitive serialization types supported by Kafka. If this property is one of these primitive types, then the Kafka key for each record will be mapped to one single Hive Column. If this property is set to &ldquo;avro&rdquo; or &ldquo;avro_confluent&rdquo;, then <code class="codeph">oracle.kafka.table.key.schema</code> is required. The Kafka key for each record will be deserialized into an Avro Object. If the Avro schema is of record type then each first level field of the record will be mapped to a single Hive column. If the Avro schema is not of Record Type, then it will be mapped to a single Hive Column named &ldquo;key&rdquo;.</p>
<p id="GUID-36570D7B-DD49-4394-9264-B73A0AC2FAD5___GOBACK">The difference between &ldquo;avro&rdquo; and &ldquo;avro_confluent&rdquo; is that the wire format for the serialization is slightly different. For &ldquo;avro&rdquo;, the entire bytes array of the key consists of the bytes of avro serialization. For &ldquo;avro_confluent&rdquo;, the bytes array consists of a magic byte, a version number, then the bytes of avro serialization of the key.</p>
</td>
</tr>
<tr class="cellalignment2">
<td class="cellalignment2" rowspan="1" colspan="1" id="d74932e106" headers="d74932e54">
<p><span class="bold">oracle.kafka.table.value.type</span></p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e106 d74932e57">
<p>Optional</p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e106 d74932e60">
<p>The value type of your record. If unset, then the value part of Kafka record will be ignored in the Hive row. Use of this property is similar to use of <code class="codeph">oracle.kafka.table.key.type</code>. The difference between them is: when the Avro Schema for Kafka value is not of record type. The whole Avro object will be mapped to a single Hive Column named &ldquo;value&rdquo; instead of &ldquo;key&rdquo;.</p>
</td>
</tr>
<tr class="cellalignment2">
<td class="cellalignment2" rowspan="1" colspan="1" id="d74932e120" headers="d74932e54">
<p><span class="bold">oracle.kafka.table.key.writer.schema</span></p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e120 d74932e57">
<p>Optional</p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e120 d74932e60">
<p>An optional writer schema for the Kafka key&rsquo;s Avro serialization. It&rsquo;s required when the reader schema for the key is different from the schema in which the keys are written to Kafka brokers. It must be the exact schema in which Kafka keys are serialized.</p>
</td>
</tr>
<tr class="cellalignment2">
<td class="cellalignment2" rowspan="1" colspan="1" id="d74932e131" headers="d74932e54">
<p><span class="bold">oracle.kafka.table.key.schema</span></p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e131 d74932e57">
<p>Required when &ldquo;oracle.kafka.table.key.type&rdquo; is &ldquo;avro&rdquo; or &ldquo;avro_confluent&rdquo;</p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e131 d74932e60">
<p>The JSON string for the Kafka key's Avro reader schema. It doesn't need to be exactly the same as the Kafka key's writer Avro schema. As long as the reader schema is compatible with the Kafka key or the converted object from the converter, it is valid. This enables you to rename Hive columns and choose what fields to keep from the Kafka key in the Hive row. If the schema in this property is different from the schema in which the Kafka keys are serialized, then <code class="codeph">oracle.kafka.table.key.writer.schema</code> is required.</p>
</td>
</tr>
<tr class="cellalignment2">
<td class="cellalignment2" rowspan="1" colspan="1" id="d74932e145" headers="d74932e54">
<p><span class="bold">oracle.kafka.table.value.writer.schema</span></p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e145 d74932e57">
<p>Optional</p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e145 d74932e60">
<p>An optional writer schema for the Kafka value&rsquo;s Avro serialization. Its use is similar to <code class="codeph">oracle.kafka.table.key.writer.schema</code>.</p>
</td>
</tr>
<tr class="cellalignment2">
<td class="cellalignment2" rowspan="1" colspan="1" id="d74932e159" headers="d74932e54">
<p><span class="bold">oracle.kafka.table.value.schema</span></p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e159 d74932e57">
<p>Required when &ldquo;oracle.kafka.table.value.type&rdquo; is &ldquo;avro&rdquo; or &ldquo;avro_confluent&rdquo;</p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e159 d74932e60">
<p>The JSON string for the Kafka value's Avro reader schema. Its use is similar to <code class="codeph">oracle.kafka.table.key.schema</code>.</p>
</td>
</tr>
<tr class="cellalignment2">
<td class="cellalignment2" rowspan="1" colspan="1" id="d74932e173" headers="d74932e54">
<p><span class="bold">oracle.kafka.table.extra.columns</span></p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e173 d74932e57">
<p>Optional, default to &ldquo;true&rdquo;</p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e173 d74932e60">
<p>A boolean flag to control whether to include extra Kafka columns: <code class="codeph">paritionid</code>, <code class="codeph">offset</code>, <code class="codeph">timestamptype</code>.</p>
</td>
</tr>
<tr class="cellalignment2">
<td class="cellalignment2" rowspan="1" colspan="1" id="d74932e193" headers="d74932e54">
<p><span class="bold">oracle.kafka.chop.partition</span></p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e193 d74932e57">
<p>Optional, default to false</p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e193 d74932e60">
<p>A Boolean flag to control whether to chop Kafka partitions into smaller chunks. This is useful when the number of Kafka partitions is small and the size of each Kafka partition is large.</p>
</td>
</tr>
<tr class="cellalignment2">
<td class="cellalignment2" rowspan="1" colspan="1" id="d74932e204" headers="d74932e54">
<p><span class="bold">oracle.kafka.partition.chunk.size</span></p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e204 d74932e57">
<p>Optional</p>
</td>
<td class="cellalignment2" rowspan="1" colspan="1" headers="d74932e204 d74932e60">
<p>When oracle.kafka.chop.partition is true, this property controls the number of Kafka records in each partition chunk. It should be set a value estimated by (Ideal size of a split)/(Average size of a Kafka record). For example, if the ideal size of a split is 256 MB and the average size of s Kafka record is 256 Bytes, then this property should be set to 1000000.</p>
</td>
</tr>
</tbody>
</table>
</div>
<!-- class="inftblhruleinformal" --></div>
<!-- class="section" --></div>
</div>
<!-- class="ind" --><!-- Start Footer -->
</div>
<!-- add extra wrapper close div-->
<footer><!--
<hr />
<table class="cellalignment1">
<tr>
<td class="cellalignment42">
<table class="cellalignment6">
<tr>
<td class="cellalignment5"><a href="GUID-395691AB-AD99-488B-96D3-CC1D8C1873B7.htm"><img width="24" height="24" src="../dcommon/gifs/leftnav.gif" alt="Go to previous page" /><br />
<span class="icon">Previous</span></a></td>
<td class="cellalignment5"><a href="GUID-6A9F1DDF-B5FF-4062-B038-8FDEF5FBEBE2.htm"><img width="24" height="24" src="../dcommon/gifs/rightnav.gif" alt="Go to next page" /><br />
<span class="icon">Next</span></a></td>
</tr>
</table>
</td>
<td class="cellalignment-copyrightlogo"><img width="144" height="18" src="../dcommon/gifs/oracle.gif" alt="Oracle" /><br />
Copyright&nbsp;&copy;&nbsp;2011, 2017, Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved.<br />
<a href="../dcommon/html/cpyr.htm">Legal Notices</a></td>
<td class="cellalignment44">
<table class="cellalignment4">
<tr>
<td class="cellalignment5"><a href="http://docs.oracle.com/bigdata/bda49/index.html"><img width="24" height="24" src="../dcommon/gifs/doclib.gif" alt="Go to Documentation Home" /><br />
<span class="icon">Home</span></a></td>
<td class="cellalignment5"><a href="toc.htm"><img width="24" height="24" src="../dcommon/gifs/toc.gif" alt="Go to Table of Contents" /><br />
<span class="icon">Contents</span></a></td>
<td class="cellalignment5"><a href="index.htm"><img width="24" height="24" src="../dcommon/gifs/index.gif" alt="Go to Index" /><br />
<span class="icon">Index</span></a></td>
<td class="cellalignment5"><a href="../dcommon/html/feedback.htm"><img width="24" height="24" src="../dcommon/gifs/feedbck2.gif" alt="Go to Feedback page" /><br />
<span class="icon">Contact Us</span></a></td>
</tr>
</table>
</td>
</tr>
</table>
--></footer>
<noscript>
<p>Scripting on this page enhances content navigation, but does not change the content in any way.</p>
</noscript>
</body>
</html>
